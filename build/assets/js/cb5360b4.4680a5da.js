"use strict";(globalThis.webpackChunkai_textbook=globalThis.webpackChunkai_textbook||[]).push([[4900],{8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>t});var s=i(6540);const r={},a=s.createContext(r);function o(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(a.Provider,{value:n},e.children)}},9125:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>t,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"cv/image-processing","title":"Image Processing in Computer Vision","description":"Image processing is a fundamental component of computer vision that involves techniques to enhance, analyze, and manipulate digital images to extract meaningful information or improve their quality for subsequent analysis.","source":"@site/docs/cv/image-processing.md","sourceDirName":"cv","slug":"/cv/image-processing","permalink":"/ai-textbook/docs/cv/image-processing","draft":false,"unlisted":false,"editUrl":"https://github.com/ai-textbook/ai-textbook/edit/main/docs/cv/image-processing.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Image Processing in Computer Vision"},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to Computer Vision","permalink":"/ai-textbook/docs/cv/introduction"},"next":{"title":"Object Detection","permalink":"/ai-textbook/docs/cv/object-detection"}}');var r=i(4848),a=i(8453);const o={sidebar_label:"Image Processing in Computer Vision"},t="Image Processing in Computer Vision",c={},l=[{value:"Overview of Image Processing",id:"overview-of-image-processing",level:2},{value:"Types of Image Processing",id:"types-of-image-processing",level:2},{value:"1. Spatial Domain Processing",id:"1-spatial-domain-processing",level:3},{value:"2. Frequency Domain Processing",id:"2-frequency-domain-processing",level:3},{value:"Common Image Enhancement Techniques",id:"common-image-enhancement-techniques",level:2},{value:"1. Histogram Equalization",id:"1-histogram-equalization",level:3},{value:"2. Noise Reduction",id:"2-noise-reduction",level:3},{value:"3. Edge Enhancement",id:"3-edge-enhancement",level:3},{value:"Feature Extraction",id:"feature-extraction",level:2},{value:"1. Edge Detection",id:"1-edge-detection",level:3},{value:"2. Corner Detection",id:"2-corner-detection",level:3},{value:"Image Segmentation",id:"image-segmentation",level:2},{value:"1. Thresholding",id:"1-thresholding",level:3},{value:"2. Region-based Segmentation",id:"2-region-based-segmentation",level:3},{value:"Color Spaces and Conversion",id:"color-spaces-and-conversion",level:2},{value:"Geometric Transformations",id:"geometric-transformations",level:2},{value:"Quality Assessment",id:"quality-assessment",level:2},{value:"Challenges in Image Processing",id:"challenges-in-image-processing",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"image-processing-in-computer-vision",children:"Image Processing in Computer Vision"})}),"\n",(0,r.jsx)(n.p,{children:"Image processing is a fundamental component of computer vision that involves techniques to enhance, analyze, and manipulate digital images to extract meaningful information or improve their quality for subsequent analysis."}),"\n",(0,r.jsx)(n.h2,{id:"overview-of-image-processing",children:"Overview of Image Processing"}),"\n",(0,r.jsx)(n.p,{children:"Image processing involves applying mathematical operations to images to enhance their quality, extract information, or transform them in meaningful ways. This foundational step often precedes higher-level computer vision tasks like object detection or recognition."}),"\n",(0,r.jsx)(n.h2,{id:"types-of-image-processing",children:"Types of Image Processing"}),"\n",(0,r.jsx)(n.h3,{id:"1-spatial-domain-processing",children:"1. Spatial Domain Processing"}),"\n",(0,r.jsx)(n.p,{children:"Operations performed directly on image pixels:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Point operations (contrast adjustment, brightness)"}),"\n",(0,r.jsx)(n.li,{children:"Neighborhood operations (smoothing, sharpening)"}),"\n",(0,r.jsx)(n.li,{children:"Geometric operations (rotation, scaling, translation)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-frequency-domain-processing",children:"2. Frequency Domain Processing"}),"\n",(0,r.jsx)(n.p,{children:"Operations performed on the frequency representation of an image:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Fourier transform-based filtering"}),"\n",(0,r.jsx)(n.li,{children:"Wavelet transforms"}),"\n",(0,r.jsx)(n.li,{children:"Noise removal in frequency domain"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"common-image-enhancement-techniques",children:"Common Image Enhancement Techniques"}),"\n",(0,r.jsx)(n.h3,{id:"1-histogram-equalization",children:"1. Histogram Equalization"}),"\n",(0,r.jsx)(n.p,{children:"Improves image contrast by redistributing pixel intensities:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import cv2\nimport numpy as np\n\ndef histogram_equalization(image):\n    # Convert to YUV color space\n    yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n    \n    # Equalize the Y channel\n    yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])\n    \n    # Convert back to BGR\n    return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n\n# Apply histogram equalization\nimage = cv2.imread('input.jpg')\nenhanced_image = histogram_equalization(image)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-noise-reduction",children:"2. Noise Reduction"}),"\n",(0,r.jsx)(n.p,{children:"Removing unwanted noise while preserving important image details:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def noise_reduction(image):\n    # Gaussian blur for noise reduction\n    denoised = cv2.GaussianBlur(image, (5, 5), 0)\n    \n    # Alternative: Bilateral filter (preserves edges)\n    # denoised = cv2.bilateralFilter(image, 9, 75, 75)\n    \n    return denoised\n"})}),"\n",(0,r.jsx)(n.h3,{id:"3-edge-enhancement",children:"3. Edge Enhancement"}),"\n",(0,r.jsx)(n.p,{children:"Sharpening edges to improve image clarity:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def edge_enhancement(image):\n    # Create sharpening kernel\n    kernel = np.array([[-1,-1,-1],\n                       [-1, 9,-1],\n                       [-1,-1,-1]])\n    \n    # Apply convolution\n    sharpened = cv2.filter2D(image, -1, kernel)\n    return sharpened\n"})}),"\n",(0,r.jsx)(n.h2,{id:"feature-extraction",children:"Feature Extraction"}),"\n",(0,r.jsx)(n.p,{children:"Feature extraction transforms raw image data into useful representations for computer vision tasks:"}),"\n",(0,r.jsx)(n.h3,{id:"1-edge-detection",children:"1. Edge Detection"}),"\n",(0,r.jsx)(n.p,{children:"Identifying points in an image where brightness changes sharply:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def detect_edges(image):\n    # Convert to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    \n    # Apply Gaussian blur\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n    \n    # Apply Canny edge detection\n    edges = cv2.Canny(blurred, 50, 150)\n    \n    return edges\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-corner-detection",children:"2. Corner Detection"}),"\n",(0,r.jsx)(n.p,{children:"Finding points where two edges meet at a corner:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def detect_corners(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    \n    # Apply Shi-Tomasi corner detection\n    corners = cv2.goodFeaturesToTrack(gray, maxCorners=100, \n                                      qualityLevel=0.01, \n                                      minDistance=10)\n    \n    return corners\n"})}),"\n",(0,r.jsx)(n.h2,{id:"image-segmentation",children:"Image Segmentation"}),"\n",(0,r.jsx)(n.p,{children:"Image segmentation partitions an image into multiple segments for more meaningful analysis:"}),"\n",(0,r.jsx)(n.h3,{id:"1-thresholding",children:"1. Thresholding"}),"\n",(0,r.jsx)(n.p,{children:"Simple segmentation by separating pixels based on intensity:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def threshold_segmentation(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    \n    # Apply binary threshold\n    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n    \n    return binary\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-region-based-segmentation",children:"2. Region-based Segmentation"}),"\n",(0,r.jsx)(n.p,{children:"Grouping pixels based on similar properties:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def watershed_segmentation(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    \n    # Apply watershed algorithm\n    _, markers = cv2.connectedComponents(binary)\n    markers = markers + 1\n    markers[unknown == 255] = 0\n    \n    markers = cv2.watershed(image, markers)\n    image[markers == -1] = [255, 0, 0]  # Mark boundaries in blue\n    \n    return image\n"})}),"\n",(0,r.jsx)(n.h2,{id:"color-spaces-and-conversion",children:"Color Spaces and Conversion"}),"\n",(0,r.jsx)(n.p,{children:"Different color spaces serve different purposes:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def color_space_conversion(image):\n    # RGB to HSV (useful for object detection based on color)\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    \n    # RGB to LAB (perceptually uniform)\n    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n    \n    return hsv, lab\n"})}),"\n",(0,r.jsx)(n.h2,{id:"geometric-transformations",children:"Geometric Transformations"}),"\n",(0,r.jsx)(n.p,{children:"Adjusting the geometric properties of images:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def geometric_transformations(image):\n    rows, cols = image.shape[:2]\n    \n    # Affine transformation (rotation, scaling, shearing)\n    pts1 = np.float32([[50,50],[200,50],[50,200]])\n    pts2 = np.float32([[10,100],[200,50],[100,250]])\n    M = cv2.getAffineTransform(pts1,pts2)\n    affine_img = cv2.warpAffine(image,M,(cols,rows))\n    \n    # Perspective transformation\n    pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n    pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n    M = cv2.getPerspectiveTransform(pts1,pts2)\n    perspective_img = cv2.warpPerspective(image, M, (300,300))\n    \n    return affine_img, perspective_img\n"})}),"\n",(0,r.jsx)(n.h2,{id:"quality-assessment",children:"Quality Assessment"}),"\n",(0,r.jsx)(n.p,{children:"Evaluating processed image quality:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def image_quality_metrics(original, processed):\n    # Peak Signal-to-Noise Ratio\n    psnr = cv2.PSNR(original, processed)\n    \n    # Structural Similarity Index\n    # Note: SSIM needs to be calculated using a specialized library\n    # from skimage.metrics import structural_similarity\n    # ssim = structural_similarity(original, processed, multichannel=True)\n    \n    return psnr\n"})}),"\n",(0,r.jsx)(n.h2,{id:"challenges-in-image-processing",children:"Challenges in Image Processing"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loss of Information"}),": Some operations can result in irreversible information loss"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Computational Complexity"}),": Advanced algorithms can be computationally expensive"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Noise Amplification"}),": Some enhancement techniques can amplify noise"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameter Tuning"}),": Many algorithms require careful parameter adjustment"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time Processing"}),": Meeting performance requirements for live applications"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Image processing provides the foundation for computer vision applications, and mastering these techniques is essential for building robust vision systems."})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);