"use strict";(globalThis.webpackChunkai_textbook=globalThis.webpackChunkai_textbook||[]).push([[8184],{2897:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"ml/deep-learning","title":"Deep Learning","description":"Deep Learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence \\"deep\\") to learn complex patterns from large amounts of data. It has revolutionized fields such as computer vision, natural language processing, and speech recognition.","source":"@site/docs/ml/deep-learning.md","sourceDirName":"ml","slug":"/ml/deep-learning","permalink":"/ai-textbook/docs/ml/deep-learning","draft":false,"unlisted":false,"editUrl":"https://github.com/ai-textbook/ai-textbook/edit/main/docs/ml/deep-learning.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Deep Learning"},"sidebar":"tutorialSidebar","previous":{"title":"Reinforcement Learning","permalink":"/ai-textbook/docs/ml/reinforcement-learning"},"next":{"title":"Introduction to NLP","permalink":"/ai-textbook/docs/nlp/introduction"}}');var r=i(4848),a=i(8453);const t={sidebar_label:"Deep Learning"},l="Deep Learning",o={},d=[{value:"Overview of Deep Learning",id:"overview-of-deep-learning",level:2},{value:"Key Characteristics:",id:"key-characteristics",level:3},{value:"Neural Network Fundamentals",id:"neural-network-fundamentals",level:2},{value:"Basic Neural Network Components",id:"basic-neural-network-components",level:3},{value:"Activation Functions",id:"activation-functions",level:2},{value:"Deep Learning with PyTorch",id:"deep-learning-with-pytorch",level:2},{value:"Basic Neural Network in PyTorch",id:"basic-neural-network-in-pytorch",level:3},{value:"Convolutional Neural Networks (CNNs)",id:"convolutional-neural-networks-cnns",level:2},{value:"Recurrent Neural Networks (RNNs)",id:"recurrent-neural-networks-rnns",level:2},{value:"Deep Learning for NLP: Transformers",id:"deep-learning-for-nlp-transformers",level:2},{value:"Training Techniques and Best Practices",id:"training-techniques-and-best-practices",level:2},{value:"1. Batch Normalization",id:"1-batch-normalization",level:3},{value:"2. Dropout for Regularization",id:"2-dropout-for-regularization",level:3},{value:"3. Learning Rate Scheduling",id:"3-learning-rate-scheduling",level:3},{value:"Transfer Learning",id:"transfer-learning",level:2},{value:"Deep Learning Applications",id:"deep-learning-applications",level:2},{value:"1. Computer Vision",id:"1-computer-vision",level:3},{value:"2. Natural Language Processing",id:"2-natural-language-processing",level:3},{value:"3. Generative Models",id:"3-generative-models",level:3},{value:"Challenges in Deep Learning",id:"challenges-in-deep-learning",level:2},{value:"Advanced Topics",id:"advanced-topics",level:2},{value:"1. Attention Mechanisms",id:"1-attention-mechanisms",level:3},{value:"2. Autoencoders",id:"2-autoencoders",level:3},{value:"3. Normalizing Flows",id:"3-normalizing-flows",level:3}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"deep-learning",children:"Deep Learning"})}),"\n",(0,r.jsx)(n.p,{children:'Deep Learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence "deep") to learn complex patterns from large amounts of data. It has revolutionized fields such as computer vision, natural language processing, and speech recognition.'}),"\n",(0,r.jsx)(n.h2,{id:"overview-of-deep-learning",children:"Overview of Deep Learning"}),"\n",(0,r.jsx)(n.p,{children:'Deep learning is inspired by the human brain\'s neural networks. It uses artificial neural networks with multiple layers between the input and output layers. The "depth" of these networks allows them to learn hierarchical representations of data, with each layer learning more abstract features than the previous one.'}),"\n",(0,r.jsx)(n.h3,{id:"key-characteristics",children:"Key Characteristics:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hierarchical Feature Learning"}),": Learns features automatically without manual feature engineering"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"End-to-End Learning"}),": Can learn from raw input to final output without intermediate manual steps"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Large-Scale Data Handling"}),": Excels with large datasets"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Versatility"}),": Applicable to various types of data (images, text, audio, time series)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"neural-network-fundamentals",children:"Neural Network Fundamentals"}),"\n",(0,r.jsx)(n.h3,{id:"basic-neural-network-components",children:"Basic Neural Network Components"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import numpy as np\nimport matplotlib.pyplot as plt\n\nclass SimpleNeuralNetwork:\n    def __init__(self, input_size, hidden_size, output_size):\n        # Initialize weights and biases randomly\n        self.W1 = np.random.randn(input_size, hidden_size) * 0.5\n        self.b1 = np.zeros((1, hidden_size))\n        self.W2 = np.random.randn(hidden_size, output_size) * 0.5\n        self.b2 = np.zeros((1, output_size))\n    \n    def sigmoid(self, x):\n        # Clip x to prevent overflow\n        x = np.clip(x, -500, 500)\n        return 1 / (1 + np.exp(-x))\n    \n    def sigmoid_derivative(self, x):\n        return x * (1 - x)\n    \n    def forward(self, X):\n        # Forward propagation\n        self.z1 = np.dot(X, self.W1) + self.b1\n        self.a1 = self.sigmoid(self.z1)\n        self.z2 = np.dot(self.a1, self.W2) + self.b2\n        self.a2 = self.sigmoid(self.z2)\n        return self.a2\n    \n    def backward(self, X, y, output):\n        # Backward propagation\n        m = X.shape[0]  # number of samples\n        \n        # Calculate gradients\n        dZ2 = output - y\n        dW2 = (1/m) * np.dot(self.a1.T, dZ2)\n        db2 = (1/m) * np.sum(dZ2, axis=0, keepdims=True)\n        \n        dA1 = np.dot(dZ2, self.W2.T)\n        dZ1 = dA1 * self.sigmoid_derivative(self.a1)\n        dW1 = (1/m) * np.dot(X.T, dZ1)\n        db1 = (1/m) * np.sum(dZ1, axis=0, keepdims=True)\n        \n        return dW1, db1, dW2, db2\n    \n    def update_parameters(self, dW1, db1, dW2, db2, learning_rate):\n        # Update weights and biases\n        self.W1 -= learning_rate * dW1\n        self.b1 -= learning_rate * db1\n        self.W2 -= learning_rate * dW2\n        self.b2 -= learning_rate * db2\n    \n    def train(self, X, y, epochs, learning_rate):\n        costs = []\n        for i in range(epochs):\n            # Forward propagation\n            output = self.forward(X)\n            \n            # Calculate cost (mean squared error)\n            cost = np.mean((output - y) ** 2)\n            costs.append(cost)\n            \n            # Backward propagation\n            dW1, db1, dW2, db2 = self.backward(X, y, output)\n            \n            # Update parameters\n            self.update_parameters(dW1, db1, dW2, db2, learning_rate)\n            \n            if i % 100 == 0:\n                print(f"Epoch {i}, Cost: {cost:.6f}")\n        \n        return costs\n\n# Example: Learning XOR function\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([[0], [1], [1], [0]])\n\nnn = SimpleNeuralNetwork(input_size=2, hidden_size=4, output_size=1)\ncosts = nn.train(X, y, epochs=1000, learning_rate=1.0)\n\n# Test the network\npredictions = nn.forward(X)\nprint("\\nPredictions after training:")\nfor i in range(len(X)):\n    print(f"Input: {X[i]}, Target: {y[i][0]}, Prediction: {predictions[i][0]:.4f}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"activation-functions",children:"Activation Functions"}),"\n",(0,r.jsx)(n.p,{children:"Activation functions introduce non-linearity, enabling neural networks to learn complex patterns."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_activation_functions():\n    x = np.linspace(-5, 5, 100)\n    \n    # Sigmoid\n    sigmoid = 1 / (1 + np.exp(-x))\n    \n    # Tanh\n    tanh = np.tanh(x)\n    \n    # ReLU\n    relu = np.maximum(0, x)\n    \n    # Leaky ReLU\n    leaky_relu = np.where(x > 0, x, x * 0.01)\n    \n    # ELU\n    alpha = 1.0\n    elu = np.where(x > 0, x, alpha * (np.exp(x) - 1))\n    \n    plt.figure(figsize=(15, 10))\n    \n    plt.subplot(2, 3, 1)\n    plt.plot(x, sigmoid, label='Sigmoid')\n    plt.title('Sigmoid')\n    plt.grid(True)\n    \n    plt.subplot(2, 3, 2)\n    plt.plot(x, tanh, label='Tanh', color='orange')\n    plt.title('Tanh')\n    plt.grid(True)\n    \n    plt.subplot(2, 3, 3)\n    plt.plot(x, relu, label='ReLU', color='green')\n    plt.title('ReLU')\n    plt.grid(True)\n    \n    plt.subplot(2, 3, 4)\n    plt.plot(x, leaky_relu, label='Leaky ReLU', color='red')\n    plt.title('Leaky ReLU')\n    plt.grid(True)\n    \n    plt.subplot(2, 3, 5)\n    plt.plot(x, elu, label='ELU', color='purple')\n    plt.title('ELU')\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n\nplot_activation_functions()\n"})}),"\n",(0,r.jsx)(n.h2,{id:"deep-learning-with-pytorch",children:"Deep Learning with PyTorch"}),"\n",(0,r.jsx)(n.h3,{id:"basic-neural-network-in-pytorch",children:"Basic Neural Network in PyTorch"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass DeepNeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size):\n        super(DeepNeuralNetwork, self).__init__()\n        \n        layers = []\n        prev_size = input_size\n        \n        for hidden_size in hidden_sizes:\n            layers.append(nn.Linear(prev_size, hidden_size))\n            layers.append(nn.ReLU())\n            # Add dropout for regularization\n            layers.append(nn.Dropout(0.2))\n            prev_size = hidden_size\n        \n        # Output layer (no activation or dropout)\n        layers.append(nn.Linear(prev_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.network(x)\n\n# Example: Training a model for binary classification\ndef train_pytorch_model():\n    # Generate sample data\n    n_samples = 1000\n    input_size = 20\n    X = torch.randn(n_samples, input_size)\n    y = (X.sum(dim=1) > 0).float().unsqueeze(1)\n    \n    # Create dataset and dataloader\n    dataset = TensorDataset(X, y)\n    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n    \n    # Create model\n    model = DeepNeuralNetwork(input_size, [64, 32, 16], 1)\n    criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Training loop\n    epochs = 100\n    for epoch in range(epochs):\n        total_loss = 0\n        for batch_X, batch_y in dataloader:\n            # Forward pass\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            \n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n        if (epoch + 1) % 20 == 0:\n            print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader):.4f}')\n    \n    return model\n\n# Train the model\n# model = train_pytorch_model()\n"})}),"\n",(0,r.jsx)(n.h2,{id:"convolutional-neural-networks-cnns",children:"Convolutional Neural Networks (CNNs)"}),"\n",(0,r.jsx)(n.p,{children:"CNNs are specialized for processing grid-like data such as images."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CNN, self).__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        \n        # Pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Dropout for regularization\n        self.dropout = nn.Dropout(0.5)\n        \n        # Fully connected layers\n        # After 3 pooling operations: 32x32 -> 16x16 -> 8x8 -> 4x4\n        # So the flattened size is 128 * 4 * 4 = 2048\n        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n    \n    def forward(self, x):\n        # Convolutional block 1\n        x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n        \n        # Convolutional block 2\n        x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n        \n        # Convolutional block 3\n        x = self.pool(F.relu(self.conv3(x)))  # 8x8 -> 4x4\n        \n        # Flatten\n        x = x.view(x.size(0), -1)  # Flatten all dimensions except batch\n        \n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x\n\n# Example usage (without actual training data)\n# cnn_model = CNN(num_classes=10)\n# sample_input = torch.randn(4, 3, 32, 32)  # 4 images, 3 channels, 32x32\n# output = cnn_model(sample_input)\n# print(f"Output shape: {output.shape}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"recurrent-neural-networks-rnns",children:"Recurrent Neural Networks (RNNs)"}),"\n",(0,r.jsx)(n.p,{children:"RNNs are designed for sequential data where the order matters."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\n\nclass RNNModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.2):\n        super(RNNModel, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # RNN layer\n        self.rnn = nn.RNN(\n            input_size, \n            hidden_size, \n            num_layers, \n            batch_first=True, \n            dropout=dropout if num_layers > 1 else 0\n        )\n        \n        # Output layer\n        self.fc = nn.Linear(hidden_size, num_classes)\n        \n    def forward(self, x):\n        # Initialize hidden state\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        \n        # Forward propagate RNN\n        out, _ = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n        \n        # Decode the hidden state of the last time step\n        out = self.fc(out[:, -1, :])\n        return out\n\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.2):\n        super(LSTMModel, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # LSTM layer\n        self.lstm = nn.LSTM(\n            input_size,\n            hidden_size,\n            num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        \n        # Output layer\n        self.fc = nn.Linear(hidden_size, num_classes)\n        \n    def forward(self, x):\n        # Initialize hidden state and cell state\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n        \n        # Forward propagate LSTM\n        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n        \n        # Decode the hidden state of the last time step\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Example usage\n# input_size = 10  # Size of each input in the sequence\n# hidden_size = 20  # Size of hidden state\n# num_layers = 2  # Number of RNN layers\n# num_classes = 5  # Number of output classes\n# sequence_length = 15  # Length of input sequence\n# batch_size = 8  # Number of samples in a batch\n\n# rnn_model = RNNModel(input_size, hidden_size, num_layers, num_classes)\n# lstm_model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\n\n# sample_input = torch.randn(batch_size, sequence_length, input_size)\n# rnn_output = rnn_model(sample_input)\n# lstm_output = lstm_model(sample_input)\n\n# print(f"RNN Output shape: {rnn_output.shape}")\n# print(f"LSTM Output shape: {lstm_output.shape}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"deep-learning-for-nlp-transformers",children:"Deep Learning for NLP: Transformers"}),"\n",(0,r.jsx)(n.p,{children:"Transformers have revolutionized NLP with self-attention mechanisms."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport math\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed_size, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.embed_size = embed_size\n        self.num_heads = num_heads\n        self.head_dim = embed_size // num_heads\n        \n        assert self.head_dim * num_heads == embed_size, "Embed size not divisible by num heads"\n        \n        self.values = nn.Linear(self.head_dim, embed_size, bias=False)\n        self.keys = nn.Linear(self.head_dim, embed_size, bias=False)\n        self.queries = nn.Linear(self.head_dim, embed_size, bias=False)\n        self.fc_out = nn.Linear(embed_size, embed_size)\n    \n    def forward(self, values, keys, query, mask):\n        N = query.shape[0]  # batch size\n        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n        \n        # Split embedding into self.num_heads different pieces\n        values = values.reshape(N, value_len, self.num_heads, self.head_dim)\n        keys = keys.reshape(N, key_len, self.num_heads, self.head_dim)\n        queries = query.reshape(N, query_len, self.num_heads, self.head_dim)\n        \n        energy = torch.einsum("nqhd,nkhd->nhqk", [queries, keys])  # (N, heads, query_len, key_len)\n        \n        if mask is not None:\n            energy = energy.masked_fill(mask == 0, float("-1e20"))\n        \n        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3)  # (N, heads, query_len, key_len)\n        \n        out = torch.einsum("nhql,nlhd->nqhd", [attention, values]).reshape(\n            N, query_len, self.embed_size\n        )  # (N, query_len, embed_size)\n        \n        out = self.fc_out(out)\n        return out\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, embed_size, num_heads, dropout, forward_expansion):\n        super(TransformerBlock, self).__init__()\n        self.attention = MultiHeadAttention(embed_size, num_heads)\n        self.norm1 = nn.LayerNorm(embed_size)\n        self.norm2 = nn.LayerNorm(embed_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(embed_size, forward_expansion * embed_size),\n            nn.ReLU(),\n            nn.Linear(forward_expansion * embed_size, embed_size)\n        )\n        \n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, value, key, query, mask):\n        attention = self.attention(value, key, query, mask)\n        \n        # Add skip connection and normalize\n        x = self.dropout(self.norm1(attention + query))\n        \n        # Feed forward\n        forward = self.feed_forward(x)\n        \n        # Add skip connection and normalize\n        out = self.dropout(self.norm2(forward + x))\n        return out\n\nclass Encoder(nn.Module):\n    def __init__(\n        self,\n        src_vocab_size,\n        embed_size,\n        num_layers,\n        heads,\n        device,\n        forward_expansion,\n        dropout,\n        max_length,\n    ):\n        super(Encoder, self).__init__()\n        self.embed_size = embed_size\n        self.device = device\n        \n        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n        self.position_embedding = nn.Embedding(max_length, embed_size)\n        \n        self.layers = nn.ModuleList(\n            [\n                TransformerBlock(\n                    embed_size,\n                    heads,\n                    dropout=dropout,\n                    forward_expansion=forward_expansion,\n                )\n                for _ in range(num_layers)\n            ]\n        )\n        \n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x, mask):\n        N, seq_length = x.shape\n        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n        \n        out = self.dropout(\n            self.word_embedding(x) + self.position_embedding(positions)\n        )\n        \n        for layer in self.layers:\n            out = layer(out, out, out, mask)\n        \n        return out\n\n# This is a simplified implementation of the transformer architecture\n# A complete implementation would include additional components like decoder\n'})}),"\n",(0,r.jsx)(n.h2,{id:"training-techniques-and-best-practices",children:"Training Techniques and Best Practices"}),"\n",(0,r.jsx)(n.h3,{id:"1-batch-normalization",children:"1. Batch Normalization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import torch\nimport torch.nn as nn\n\nclass NetworkWithBatchNorm(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size):\n        super(NetworkWithBatchNorm, self).__init__()\n        \n        layers = []\n        prev_size = input_size\n        \n        for hidden_size in hidden_sizes:\n            layers.append(nn.Linear(prev_size, hidden_size))\n            layers.append(nn.BatchNorm1d(hidden_size))  # Batch normalization\n            layers.append(nn.ReLU())\n            prev_size = hidden_size\n        \n        layers.append(nn.Linear(prev_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.network(x)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-dropout-for-regularization",children:"2. Dropout for Regularization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class NetworkWithDropout(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.5):\n        super(NetworkWithDropout, self).__init__()\n        \n        layers = []\n        prev_size = input_size\n        \n        for i, hidden_size in enumerate(hidden_sizes):\n            layers.append(nn.Linear(prev_size, hidden_size))\n            layers.append(nn.ReLU())\n            \n            # Add dropout after each hidden layer except the last one\n            if i < len(hidden_sizes) - 1:\n                layers.append(nn.Dropout(dropout_rate))\n            \n            prev_size = hidden_size\n        \n        layers.append(nn.Linear(prev_size, output_size))\n        \n        self.network = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.network(x)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"3-learning-rate-scheduling",children:"3. Learning Rate Scheduling"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n\ndef create_scheduler_example():\n    model = nn.Linear(10, 1)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Step scheduler: reduce LR by factor of 0.1 every 30 epochs\n    step_scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n    \n    # Plateau scheduler: reduce LR when validation loss stops improving\n    plateau_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n    \n    return optimizer, step_scheduler, plateau_scheduler\n"})}),"\n",(0,r.jsx)(n.h2,{id:"transfer-learning",children:"Transfer Learning"}),"\n",(0,r.jsx)(n.p,{children:"Using pre-trained models and fine-tuning them for specific tasks."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import torchvision.models as models\nimport torch.nn as nn\n\ndef create_transfer_learning_model(num_classes, pretrained=True):\n    # Load a pre-trained ResNet model\n    model = models.resnet18(pretrained=pretrained)\n    \n    # Freeze all parameters\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    # Replace the final fully connected layer to adapt to our number of classes\n    num_features = model.fc.in_features\n    model.fc = nn.Linear(num_features, num_classes)\n    \n    return model\n\ndef create_fine_tuning_model(num_classes, pretrained=True):\n    # Load a pre-trained ResNet model\n    model = models.resnet18(pretrained=pretrained)\n    \n    # Keep some layers frozen, fine-tune others\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    # Fine-tune the last few layers\n    for param in model.layer4.parameters():\n        param.requires_grad = True\n    \n    for param in model.fc.parameters():\n        param.requires_grad = True\n    \n    # Adjust the final layer\n    num_features = model.fc.in_features\n    model.fc = nn.Linear(num_features, num_classes)\n    \n    return model\n"})}),"\n",(0,r.jsx)(n.h2,{id:"deep-learning-applications",children:"Deep Learning Applications"}),"\n",(0,r.jsx)(n.h3,{id:"1-computer-vision",children:"1. Computer Vision"}),"\n",(0,r.jsx)(n.p,{children:"Deep learning models like CNNs have achieved state-of-the-art results in image classification, object detection, and segmentation."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def simple_image_classifier():\n    """\n    A simple example of how CNNs are used in computer vision.\n    This would require actual image data and preprocessing.\n    """\n    import torch\n    import torch.nn as nn\n    \n    # Define a simple CNN for image classification\n    class ImageClassifier(nn.Module):\n        def __init__(self, num_classes=10):\n            super(ImageClassifier, self).__init__()\n            \n            # Convolutional layers\n            self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n            self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n            self.pool = nn.MaxPool2d(2, 2)\n            self.dropout = nn.Dropout(0.5)\n            \n            # Fully connected layers\n            self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Assuming input is 32x32\n            self.fc2 = nn.Linear(512, num_classes)\n        \n        def forward(self, x):\n            x = self.pool(torch.relu(self.conv1(x)))\n            x = self.pool(torch.relu(self.conv2(x)))\n            \n            x = x.view(-1, 64 * 8 * 8)  # Flatten\n            x = torch.relu(self.fc1(x))\n            x = self.dropout(x)\n            x = self.fc2(x)\n            \n            return x\n    \n    return ImageClassifier()\n\n# img_classifier = simple_image_classifier()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-natural-language-processing",children:"2. Natural Language Processing"}),"\n",(0,r.jsx)(n.p,{children:"Transformers and RNNs are widely used in NLP for tasks like translation, summarization, and question answering."}),"\n",(0,r.jsx)(n.h3,{id:"3-generative-models",children:"3. Generative Models"}),"\n",(0,r.jsx)(n.p,{children:"Deep learning is used to create generative models like GANs and VAEs."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class Generator(nn.Module):\n    def __init__(self, latent_dim, img_shape):\n        super(Generator, self).__init__()\n        self.img_shape = img_shape\n        \n        def block(in_feat, out_feat, normalize=True):\n            layers = [nn.Linear(in_feat, out_feat)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n        \n        self.model = nn.Sequential(\n            *block(latent_dim, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))),\n            nn.Tanh()\n        )\n    \n    def forward(self, z):\n        img = self.model(z)\n        img = img.view(img.size(0), *self.img_shape)\n        return img\n\nclass Discriminator(nn.Module):\n    def __init__(self, img_shape):\n        super(Discriminator, self).__init__()\n        \n        self.model = nn.Sequential(\n            nn.Linear(int(np.prod(img_shape)), 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1)\n        validity = self.model(img_flat)\n        return validity\n"})}),"\n",(0,r.jsx)(n.h2,{id:"challenges-in-deep-learning",children:"Challenges in Deep Learning"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data Requirements"}),": Deep learning models often require large amounts of data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Computational Resources"}),": Training deep models requires significant computational power"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Overfitting"}),": Models can memorize training data instead of learning generalizable patterns"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Interpretability"}),': Deep models are often considered "black boxes"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hyperparameter Tuning"}),": Finding optimal hyperparameters can be time-consuming"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Vanishing/Exploding Gradients"}),": Problems with training very deep networks"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"advanced-topics",children:"Advanced Topics"}),"\n",(0,r.jsx)(n.h3,{id:"1-attention-mechanisms",children:"1. Attention Mechanisms"}),"\n",(0,r.jsx)(n.p,{children:"Attention allows models to focus on relevant parts of the input when making predictions."}),"\n",(0,r.jsx)(n.h3,{id:"2-autoencoders",children:"2. Autoencoders"}),"\n",(0,r.jsx)(n.p,{children:"Neural networks used for unsupervised learning of efficient codings."}),"\n",(0,r.jsx)(n.h3,{id:"3-normalizing-flows",children:"3. Normalizing Flows"}),"\n",(0,r.jsx)(n.p,{children:"Advanced generative models for complex probability distributions."}),"\n",(0,r.jsx)(n.p,{children:"Deep learning continues to evolve rapidly, with new architectures and techniques being developed regularly. The field has achieved remarkable success in solving complex problems across various domains and continues to be an active area of research and application."})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var s=i(6540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);